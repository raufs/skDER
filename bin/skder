#!/usr/bin/env python3

### Program: skder
### Author: Rauf Salamzade
### Kalan Lab
### UW Madison, Department of Medical Microbiology and Immunology

# BSD 3-Clause License
#
# Copyright (c) 2023, Rauf Salamzade
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this
#    list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its
#    contributors may be used to endorse or promote products derived from
#    this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

import os
import sys
from skDER import util
import shutil
from time import sleep
import argparse
import gzip
from collections import defaultdict
import pkg_resources
import math
import multiprocessing
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

version = pkg_resources.require("skDER")[0].version

ACCEPTED_SUFFICES = set(['fasta', 'fas', 'fna', 'fa'])
VALID_GTDB_RELEASES = set(['R214', 'R220'])
PRESELECTED_ANI_CUTOFFS = [90.0, 95.0, 97.0, 98.0, 99.0, 99.5]
PRESELECTED_AF_CUTOFFS = [10.0, 25.0, 50.0, 75.0, 90.0]

def create_parser():
	""" Parse arguments """
	parser = argparse.ArgumentParser(description="""
	Program: skder
	Author: Rauf Salamzade
	Affiliation: Kalan Lab, UW Madison, Department of Medical Microbiology and Immunology

	skDER: efficient & high-resolution dereplication of microbial genomes to select 
		   representative genomes.

	skDER will perform dereplication of genomes using skani average nucleotide identity 
	(ANI) and aligned fraction (AF) estimates and either a dynamic programming or 
	greedy-based based approach. It assesses such pairwise ANI & AF estimates to determine 
	whether two genomes are similar to each other and then chooses which genome is better 
	suited to serve as a representative based on assembly N50 (favoring the more contiguous 
	assembly) and connectedness (favoring genomes deemed similar to a greater number of 
	alternate genomes).
	""", formatter_class=argparse.RawTextHelpFormatter)

	parser.add_argument('-g', '--genomes', nargs='+', help='Genome assembly files in (gzipped) FASTA format\n(accepted suffices are: *.fasta,\n*.fa, *.fas, or *.fna) [Optional].', required=False, default=[])
	parser.add_argument('-t', '--taxa-name', help='Genus or species identifier from GTDB for which to\ndownload genomes for and include in\ndereplication analysis [Optional].', required=False, default=None)
	parser.add_argument('-r', '--gtdb-release', help='Which GTDB release to use if -t argument issued [Default is R220].', default="R220")
	parser.add_argument('-o', '--output-directory', help='Output directory.', required=True)
	parser.add_argument('-d', '--dereplication-mode', help='Whether to use a "dynamic" (more concise) or "greedy" (more\ncomprehensive) approach to selecting representative genomes.\n[Default is "dynamic"]', required=False, default="dynamic")
	parser.add_argument('-i', '--percent-identity-cutoff', type=float, help="ANI cutoff for dereplication [Default is 99.0].", required=False, default=99.0)
	parser.add_argument('-tc', '--test-cutoffs', action='store_true', help="Assess clustering using various pre-selected cutoffs.", required=False, default=False)
	parser.add_argument('-f', '--aligned-fraction-cutoff', type=float, help="Aligned cutoff threshold for dereplication - only needed by\none genome [Default is 90.0].", required=False, default=90.0)
	parser.add_argument('-a', '--max-af-distance-cutoff', type=float, help="Maximum difference for aligned fraction between a pair to\nautomatically disqualify the genome with a higher\nAF from being a representative.", required=False, default=10.0)
	parser.add_argument('-p', '--skani-triangle-parameters', help="Options for skani triangle. Note ANI and AF cutoffs\nare specified separately and the -E parameter is always\nrequested. [Default is \"\"].", default="", required=False)
	parser.add_argument('-c', '--cpus', type=int, help="Number of CPUs to use.", required=False, default=1)
	parser.add_argument('-s', '--sanity-check', action='store_true', help="Confirm each FASTA file provided or downloaded is actually\na FASTA file. Makes it slower, but generally\ngood practice.", required=False, default=False)
	parser.add_argument('-n', '--determine-clusters', action='store_true', help="Perform secondary clustering to assign non-representative\ngenomes to their closest representative genomes.", required=False, default=False)
	parser.add_argument('-l', '--symlink', action='store_true', help="Symlink representative genomes in results subdirectory\ninstead of performing a copy of the files.", required=False, default=False)
	parser.add_argument('-b', '--index-locally', action='store_true', help="Build indices locally instead of in the directory of input genomes.", required=False, default=False)
	parser.add_argument('-u', '--ncbi-nlm-url', action='store_true', help="Try using the NCBI ftp address with '.nlm' for\nncbi-genome-download if there are issues.", required=False, default=False)
	parser.add_argument('-v', '--version', action='store_true', help="Report version of skDER.", required=False, default=False)
	args = parser.parse_args()
	return args

def skder_main():
	if len(sys.argv)>1 and ('-v' in set(sys.argv) or '--version' in set(sys.argv)):
		sys.stderr.write('Version of skDER being used is: ' + str(version) + '\n')
		sys.exit(0)
	
	# Parse arguments
	myargs = create_parser()

	genomes = myargs.genomes
	taxa_name = None
	if myargs.taxa_name:
		taxa_name = myargs.taxa_name.strip('"')
	gtdb_release = myargs.gtdb_release.upper()
	outdir = os.path.abspath(myargs.output_directory) + '/'
	selection_mode = myargs.dereplication_mode.lower()
	percent_identity_cutoff = myargs.percent_identity_cutoff
	aligned_fraction_cutoff = myargs.aligned_fraction_cutoff
	skani_triangle_parameters = myargs.skani_triangle_parameters
	max_af_distance_cutoff = myargs.max_af_distance_cutoff
	test_cutoffs_flag = myargs.test_cutoffs
	cpus = myargs.cpus
	symlink_flag = myargs.symlink
	determine_clusters_flag = myargs.determine_clusters
	sanity_check = myargs.sanity_check
	index_locally_flag = myargs.index_locally
	ncbi_nlm_url_flag = myargs.ncbi_nlm_url

	ngd_url = "https://ftp.ncbi.nih.gov/genomes"
	if ncbi_nlm_url_flag:
		ngd_url = "https://ftp.ncbi.nlm.nih.gov/genomes"

	try:
		assert(selection_mode in set(['dynamic', 'greedy']))
	except:
		sys.stderr.write('Selection mode requested not valid, must be either "greedy" or  "dynamic".')
		sys.exit(1)

	try:
		assert(gtdb_release in VALID_GTDB_RELEASES)
	except:
		sys.stderr.write('GTDB release requested is not valid. Valid options include: %s\n' % ' '.join(VALID_GTDB_RELEASES))
		sys.exit(1)

	if os.path.isdir(outdir):
		sys.stderr.write("Output directory already exists! Overwriting in 5 seconds...\n")
		sleep(5)

	util.setupDirectories([outdir])

	# Create logging object
	log_file = outdir + 'Progress.log'
	logObject = util.createLoggerObject(log_file)
	parameters_file = outdir + 'Command_Issued.txt'
	sys.stdout.write('Running version %s\n' % version)
	sys.stdout.write("Appending command issued for future records to: %s\n" % parameters_file)
	sys.stdout.write("Logging more details at: %s\n" % log_file)
	logObject.info("\nNEW RUN!!!\n**************************************")
	logObject.info('Running version %s' % version)
	logObject.info("Appending command issued for future records to: %s" % parameters_file)

	parameters_handle = open(parameters_file, 'a+')
	parameters_handle.write(' '.join(sys.argv) + '\n')
	parameters_handle.close()

	specified_ani_cutoff = percent_identity_cutoff

	specified_af_cutoff = aligned_fraction_cutoff
	if determine_clusters_flag and selection_mode == 'dynamic':
		aligned_fraction_cutoff = max([aligned_fraction_cutoff - 20.0, 0.0])

	all_genomes_listing_file = outdir + 'All_Genomes_Listing.txt'

	if taxa_name != "None" and taxa_name != None:
		# Step 0: Download GTDB listing file from lsaBGC git repo, parse GTDB information 
		# file, get list of Genbank accessions, and perform dry-run with ncbi-genome-download 
		# if requested.
		sys.stdout.write("GTDB listing file not available, using wget to download it.\n")
		logObject.info("\nGTDB listing file not available, using wget to download it.")
		wget_cmd = ['wget', 'https://github.com/raufs/gtdb_gca_to_taxa_mappings/raw/main/GTDB_' + gtdb_release + '_Information.txt.gz', '-P', outdir]
		gtdb_listing_file = outdir + "GTDB_" + gtdb_release + "_Information.txt.gz"
		util.runCmd(wget_cmd, logObject, check_files=[gtdb_listing_file])

		genbank_accession_listing_file = outdir + 'NCBI_Genbank_Accession_Listing.txt'
		sys.stdout.write("--------------------\nStep 0\n--------------------\nBeginning by assessing which genomic assemblies are available for the taxa %s in GTDB %s\n" % (taxa_name, gtdb_release))
		logObject.info("\n--------------------\nStep 0\n--------------------\nBeginning by assessing which genomic assemblies are available for the taxa %s in GTDB %s" % (taxa_name, gtdb_release))

		if not os.path.isfile(genbank_accession_listing_file):
			genbank_accession_listing_handle = open(genbank_accession_listing_file, 'w')
			with gzip.open(gtdb_listing_file, 'rt') as ogtdb:
				for line in ogtdb:
					line = line.strip('\n')
					ls = line.split('\t')
					if ls[0] == 'none': continue
					if len(taxa_name.split()) == 1:
						if ls[1] == taxa_name:
							genbank_accession_listing_handle.write(ls[0] + '\n')
					elif len(taxa_name.split()) == 2:
						if ls[2] == taxa_name:
							genbank_accession_listing_handle.write(ls[0] + '\n')
			genbank_accession_listing_handle.close()

		ogalf = open(genbank_accession_listing_file)
		accession_count = len(ogalf.readlines())
		ogalf.close()

		if accession_count == 0:
			sys.stderr.write('Warning: no genomes found to belong the genus or species specified in GTDB.\n')
			logObject.info('Warning: no genomes found to belong the genus or species specified in GTDB.')
		else:
			genome_listing_file = outdir + 'NCBI_Genomes_from_Genbank_for_Taxa.txt'
			if not os.path.isfile(genome_listing_file):
				if accession_count != 0:
					ngd_dry_cmd = ['ncbi-genome-download', '--dry-run', '--section', 'genbank', '-u', ngd_url, '-A', genbank_accession_listing_file, 'bacteria', '>', genome_listing_file]
					util.runCmd(ngd_dry_cmd, logObject, check_files=[genome_listing_file])
				else:
					of = open(genome_listing_file, 'w')
					of.close()

			oglf = open(genome_listing_file)
			genome_count = len(oglf.readlines())
			oglf.close()
			if genome_count == 0:
				sys.stderr.write('Warning: no genomes could be downloaded with ncbi-genome-download.\n')
				logObject.info('Warning: no genomes could be downloaded with ncbi-genome-download.')
			else:
				# Download all genomes in FASTA format & prodigal gene calling
				genomes_directory = outdir + 'gtdb_ncbi_genomes/'
				if not os.path.isfile(all_genomes_listing_file):
					if genome_count != 0:
						ngd_real_cmd = ['ncbi-genome-download', '--formats', 'fasta', '--retries', '2', '--section', 'genbank', '-u', ngd_url,
							        '-A', genbank_accession_listing_file, '-o', genomes_directory, '--flat-output',  'bacteria']
						util.runCmd(ngd_real_cmd, logObject, check_directories=[genomes_directory])

						gca_to_species_name = {}
						with gzip.open(gtdb_listing_file, 'rt') as ogtdb:
								for line in ogtdb:
									line = line.strip('\n')
									ls = line.split('\t')
									if ls[0] == 'none': continue
									gca = ls[0]
									sp_name = '_'.join(ls[2].split())
									gca_to_species_name[gca] = sp_name
									
						gf_listing_handle = open(all_genomes_listing_file, 'a+')
						for gf in os.listdir(genomes_directory):
							gfile = genomes_directory + gf 
							suffix = '.gz'.join(gf.split('.gz')[:-1]).split('.')[-1].lower()
							if not suffix in ACCEPTED_SUFFICES: continue
							if sanity_check:
								assert (util.is_fasta(gfile))
							gca = '_'.join(gf.split('_')[:2])
							species_name = gca_to_species_name[gca]
							renamed_gfile = genomes_directory + species_name + '_' + gca + '.fasta.gz'
							os.rename(gfile, renamed_gfile)
							gf_listing_handle.write(renamed_gfile + '\n')
						gf_listing_handle.close()

	if genomes:
		symlink_genomes_directory = outdir + 'local_genomes/' 
		util.setupDirectories([symlink_genomes_directory])
		gf_listing_handle = open(all_genomes_listing_file, 'a+')
		for gf in genomes:
			gf = os.path.abspath(gf)
			suffix = gf.split('.')[-1].lower()
			if gf.endswith('.gz'):
				suffix = '.gz'.join(gf.split('.gz')[:-1]).split('.')[-1].lower()
			if not suffix in ACCEPTED_SUFFICES: continue
			if sanity_check:
				assert(util.is_fasta(gf))
			gf_listing_handle.write(gf + '\n')
		gf_listing_handle.close()

	number_of_genomes = None
	try:
		assert(os.path.isfile(all_genomes_listing_file))
		with open(all_genomes_listing_file) as oaglf:
			number_of_genomes= len(oaglf.readlines())
		assert(number_of_genomes >= 2)
	except Exception as e:
		logObject.error('Fewer than 2 genomes downloaded / provided. Exiting ...')
		sys.stderr.write('Fewer than 2 genomes downloaded / provided. Exiting ...\n')
		sys.exit(1)

	# calculate N50s
	genomes = []
	with open(all_genomes_listing_file) as oaglf:
		for line in oaglf:
			genome_path = line.strip()
			genomes.append(genome_path)

	genome_count = len(genomes)
	chunk_size = math.ceil(genome_count/cpus)
	genome_chunks = util.divide_chunks(genomes, chunk_size)

	n50_dir = outdir + 'Assembly_N50s/'
	util.setupDirectories([n50_dir])
	n50_inputs = []
	for i, gc in enumerate(genome_chunks):
		n50_chunk_file = n50_dir + 'chunk_' + str(i) + '.txt'
		n50_inputs.append([gc, n50_chunk_file, index_locally_flag])

	p = multiprocessing.Pool(cpus)
	p.map(util.compute_n50, n50_inputs)
	p.close()

	# concatenate N50 results into a single file
	concat_n50_result_file = outdir + 'Concatenated_N50.txt'
	os.system('time find %s -maxdepth 1 -type f | xargs cat >> %s' % (n50_dir, concat_n50_result_file))

	# remove the directory with N50 stats after concatenating info into a single file.
	shutil.rmtree(n50_dir)

	# run skani triangle
	skani_result_file = outdir + 'Skani_Triangle_Edge_Output.txt'
	skani_triangle_cmd = ['skani', 'triangle', '-l', all_genomes_listing_file, 
			      '--min-af', str(aligned_fraction_cutoff), '-E', skani_triangle_parameters, '-t', str(cpus), '-o', skani_result_file]
	if test_cutoffs_flag:
		min_af_cutoff = min(PRESELECTED_AF_CUTOFFS)
		if selection_mode == 'dynamic':
			min_af_cutoff = max([min_af_cutoff - 20.0, 0.0])
		skani_triangle_cmd = ['skani', 'triangle', '-l', all_genomes_listing_file,
			      '--min-af', str(min_af_cutoff), '-E', skani_triangle_parameters, '-t', str(cpus), '-o', skani_result_file]
	util.runCmd(skani_triangle_cmd, logObject, check_files=[skani_result_file])

	if test_cutoffs_flag:
		skder_result_dir = outdir + 'skDER_Result/'
		util.setupDirectories([skder_result_dir])
		
		heatmap_df = [['ANI/AF'] + [str(x) for x in PRESELECTED_AF_CUTOFFS]]
		for ani_cutoff in PRESELECTED_ANI_CUTOFFS:
			row_data = [str(ani_cutoff)]
			for af_cutoff in PRESELECTED_AF_CUTOFFS:
				skder_result_file = skder_result_dir + 'skDER_Results_ANI' + str(ani_cutoff) + '_AF' + str(af_cutoff) + '.txt'
				if selection_mode == 'dynamic':
					# perform representative selection using dynamic method (default)
					skder_core_prog = 'skDERcore'
					skder_core_cmd = [skder_core_prog, skani_result_file, concat_n50_result_file, str(ani_cutoff), 
									str(af_cutoff), str(max_af_distance_cutoff), '>', skder_result_file]
					util.runCmd(skder_core_cmd, logObject, check_files=[skder_result_file])

				elif selection_mode == 'greedy':
					# perform representative selection using greedy method
					skder_sum_prog = 'skDERsum'
					genome_summary_file = outdir + 'Genome_Information_for_Greedy_Clustering.txt'
					skder_sum_cmd = [skder_sum_prog, skani_result_file, concat_n50_result_file, str(ani_cutoff), 
									str(af_cutoff), '>', genome_summary_file]
					util.runCmd(skder_sum_cmd, logObject, check_files=[genome_summary_file])

					sorted_genome_summary_file = outdir + 'Genome_Information_for_Greedy_Clustering.sorted.txt'
					sort_cmd = ['sort', '-k', '2', '-gr', genome_summary_file, '>', sorted_genome_summary_file]
					util.runCmd(sort_cmd, logObject, check_files=[sorted_genome_summary_file])

					# greedy clustering
					skder_result_handle = open(skder_result_file, 'w')
					already_accounted = set([])
					with open(sorted_genome_summary_file) as osgsf:
						for line in osgsf:
							line = line.strip('\n')
							ls = line.split('\t')
							curr_g = ls[0]
							if curr_g in already_accounted: continue
							ls = line.split('\t')
							for g in ls[2].split('; '):
								already_accounted.add(g)
							skder_result_handle.write(curr_g + '\n')
					skder_result_handle.close()
				rep_genome_count = 0 
				with open(skder_result_file) as osrf:
					for line in osrf:
						rep_genome_count += 1
				row_data.append(rep_genome_count)
			heatmap_df.append(row_data)

		headers = heatmap_df.pop(0) 
		heatmap_pd_df = pd.DataFrame(heatmap_df, columns=headers)
		heatmap_pd_df.set_index('ANI/AF', inplace=True)
		
		sys.stdout.write("\nNumber of representative genomes selected:\n")
		sys.stdout.write(str(heatmap_pd_df) + '\n')
		
		heatmap_pdf = outdir + 'Parameter_Impacts_Overview.pdf'
		sns.set_theme(style='white')
		p = sns.heatmap(heatmap_pd_df, annot=True, fmt=',d', cmap='Reds', linewidth=0.5).set_title('Number of representative genomes selected')
		plt.ylabel('Average Nucleotide Identity Cutoff')
		plt.xlabel('Aligned Fraction Cutoff')
		plt.savefig(heatmap_pdf, format='pdf')

		# close logging object and exit
		logObject.info('******************\nskDER in testing mode finished!\n******************\nHeatmap with number of representative genomes from different cutoffs can be found at: %s' % heatmap_pdf)
		sys.stdout.write('******************\nskDER in testing mode finished!\n******************\nHeatmap with number of representative genomes from different cutoffs can be found at: %s\n' % heatmap_pdf)
		util.closeLoggerObject(logObject)

	else:
		skder_result_file = outdir + 'skDER_Results.txt'

		if selection_mode == 'dynamic':
			# perform representative selection using dynamic method (default)
			skder_core_prog = 'skDERcore'
			skder_core_cmd = [skder_core_prog, skani_result_file, concat_n50_result_file, str(specified_ani_cutoff), 
							str(specified_af_cutoff), str(max_af_distance_cutoff), '>', skder_result_file]
			util.runCmd(skder_core_cmd, logObject, check_files=[skder_result_file])

		elif selection_mode == 'greedy':
			# perform representative selection using greedy method
			skder_sum_prog = 'skDERsum'
			genome_summary_file = outdir + 'Genome_Information_for_Greedy_Clustering.txt'
			skder_sum_cmd = [skder_sum_prog, skani_result_file, concat_n50_result_file, str(specified_ani_cutoff), 
							str(aligned_fraction_cutoff), '>', genome_summary_file]
			util.runCmd(skder_sum_cmd, logObject, check_files=[genome_summary_file])

			sorted_genome_summary_file = outdir + 'Genome_Information_for_Greedy_Clustering.sorted.txt'
			sort_cmd = ['sort', '-k', '2', '-gr', genome_summary_file, '>', sorted_genome_summary_file]
			util.runCmd(sort_cmd, logObject, check_files=[sorted_genome_summary_file])

			# greedy clustering
			skder_result_handle = open(skder_result_file, 'w')
			already_accounted = set([])
			with open(sorted_genome_summary_file) as osgsf:
				for line in osgsf:
					line = line.strip('\n')
					ls = line.split('\t')
					curr_g = ls[0]
					if curr_g in already_accounted: continue
					ls = line.split('\t')
					for g in ls[2].split('; '):
						already_accounted.add(g)
					skder_result_handle.write(curr_g + '\n')
			skder_result_handle.close()

		# copy over genomes which are non-redundant to a separate directory
		skder_drep_dir = outdir + 'Dereplicated_Representative_Genomes/'	
		if not os.path.isdir(skder_drep_dir):
			util.setupDirectories([skder_drep_dir])

		with open(skder_result_file) as osrf:
			for line in osrf:
				genome_path = line.strip()
				try:
					if symlink_flag:
						symlink_file = skder_drep_dir + genome_path.split('/')[-1]
						os.symlink(genome_path, symlink_file)
					else:
						shutil.copy2(genome_path, skder_drep_dir)
					
				except:
					sys.stderr.write('Warning: issues copying over representative genome %s to final dereplicated sub-directory.\n' % genome_path)
					logObject.warning('Issues copying over representative genome %s to final dereplicated sub-directory.' % genome_path)

		# assign non-representative genomes to representative genomes (i.e. determine clusters) if requested		
		if determine_clusters_flag:
			skder_cluster_result_file = outdir + 'skDER_Clustering.txt'

			scrf_handle = open(skder_cluster_result_file, 'w')
			scrf_handle.write('genome\tnearest_representative_genome\taverage_nucleotide_identity\talignment_fraction\tmatch_category\n')
			rep_genomes = set([])
			with open(skder_result_file) as osrf:
				for line in osrf:
					line = line.strip()
					rep_genomes.add(line)
					scrf_handle.write(line + '\t' + line + '\t100.0\t100.0\trepresentative_to_self\n')

			best_rep_match_at_default_af = defaultdict(lambda: [set(["NA"]), 0.0, 0.0])
			best_rep_match_at_loose_af = defaultdict(lambda: [set(["NA"]), 0.0, 0.0])
			with open(skani_result_file) as osrf:
				for i, line in enumerate(osrf):
					if i == 0: continue
					line = line.strip()
					ref, que, ani, raf, qaf, _, _ = line.split('\t')
					ani = float(ani)
					raf = float(raf)
					qaf = float(qaf)
					if que in rep_genomes and not ref in rep_genomes:
						if raf >= specified_af_cutoff:
							if ani > best_rep_match_at_default_af[ref][1]:
								best_rep_match_at_default_af[ref] = [set([que]), ani, raf]
							elif ani == best_rep_match_at_default_af[ref][1]:
								if raf > best_rep_match_at_default_af[ref][2]:
									best_rep_match_at_default_af[ref] = [set([que]), ani, raf]
								elif raf == best_rep_match_at_default_af[ref][2]:
									best_rep_match_at_default_af[ref][0].add(que)
						else:
							if ani > best_rep_match_at_loose_af[ref][1]:
								best_rep_match_at_loose_af[ref] = [set([que]), ani, raf]
							elif ani == best_rep_match_at_loose_af[ref][1]:
								if raf > best_rep_match_at_loose_af[ref][2]:
									best_rep_match_at_loose_af[ref] = [set([que]), ani, raf]
								elif raf == best_rep_match_at_loose_af[ref][2]:
									best_rep_match_at_loose_af[ref][0].add(que)

					if ref in rep_genomes and not que in rep_genomes:
						if qaf >= specified_af_cutoff:
							if ani > best_rep_match_at_default_af[que][1]:
								best_rep_match_at_default_af[que] = [set([ref]), ani, qaf]
							elif ani == best_rep_match_at_default_af[que][1]:
								if qaf > best_rep_match_at_default_af[que][2]:
									best_rep_match_at_default_af[que] = [set([ref]), ani, qaf]
								elif qaf == best_rep_match_at_default_af[que][2]:
									best_rep_match_at_default_af[que][0].add(ref)
						else:
							if ani > best_rep_match_at_loose_af[que][1]:
								best_rep_match_at_loose_af[que] = [set([ref]), ani, qaf]
							elif ani == best_rep_match_at_loose_af[que][1]:
								if qaf > best_rep_match_at_loose_af[que][2]:
									best_rep_match_at_loose_af[que] = [set([ref]), ani, qaf]
								elif qaf == best_rep_match_at_loose_af[que][2]:
									best_rep_match_at_loose_af[que][0].add(ref)				
												
			strict_nearest_ref_found = set([])
			for gen in best_rep_match_at_default_af:
				if best_rep_match_at_default_af[gen][0] != 'NA':
					strict_nearest_ref_found.add(gen)
					if best_rep_match_at_default_af[gen][1] >= specified_ani_cutoff:
						scrf_handle.write('\t'.join([gen, ', '.join(best_rep_match_at_default_af[gen][0]), 
										str(best_rep_match_at_default_af[gen][1]), 
										str(best_rep_match_at_default_af[gen][2]), 
										'within_cutoffs_requested']) + '\n')
					else:
						scrf_handle.write('\t'.join([gen, ', '.join(best_rep_match_at_default_af[gen][0]), 
						str(best_rep_match_at_default_af[gen][1]), 
						str(best_rep_match_at_default_af[gen][2]), 
						'outside_cutoffs_requested']) + '\n')
			for gen in best_rep_match_at_loose_af:
				if gen in strict_nearest_ref_found: continue
				scrf_handle.write('\t'.join([gen, ', '.join(best_rep_match_at_loose_af[gen][0]), 
								str(best_rep_match_at_loose_af[gen][1]), 
								str(best_rep_match_at_loose_af[gen][2]), 
								'outside_cutoffs_requested']) + '\n')

			scrf_handle.close()

		# close logging object and exit
		logObject.info('******************\nskDER finished!\n******************\nDirectory with representative genomes can be found at: %s' % skder_drep_dir)
		sys.stdout.write('******************\nskDER finished!\n******************\nDirectory with representative genomes can be found at: %s\n' % skder_drep_dir)
		util.closeLoggerObject(logObject)

	# create completion file for workflows to check
	completion_file = outdir + 'COMPLETED.txt'
	os.system('echo "skDER completed successfully!" > %s' % completion_file)
	assert(os.path.isfile(completion_file))
	sys.exit(0)

if __name__ == '__main__':
	multiprocessing.set_start_method('fork')
	skder_main()
